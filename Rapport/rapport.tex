\documentclass[12pt,a4paper]{article}
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------       Package
\usepackage[utf8]{inputenc}
\usepackage[left=2.5cm, right=2.5cm, top=3.2cm, bottom=2cm, headsep=2.5cm]{geometry}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{natbib}

\usepackage{float}

%----- ABSTRACT

%----- En tête

\title{Reconstruction d'un tableau sans reflets à partir de photos prises sous des angles différents}
\date{13 Mars 2014}
\author{Théophile DALENS et Jean CAILLÉ}

\begin{document}
\maketitle

%------------------------------------------> SECTION Introduction
\section{Introduction}
Il devient aujourd'hui facile d'obtenir des photos de chefs-d'oeuvre dans un musée. Toutefois la présence de lumières couplés aux vernis et aux cadre en verres entraine sur la plupart des photos prises des reflets peu plaisants à l'oeil. En multipliant les points de vue, nous allons voir qu'il est possible de supprimer ces reflets et d'obtenir une photo proche de celle prise dans des conditions idéales.

%------------------------------------------> SECTION Méthode
\section{Méthode}

La méthode proposée par l'article ne s'attache pas à traiter le tableau sous l'angle de la reconnaissance d'image (reconnaitre par exemple les aplats de couleurs et supprimer les reflets à partir de cette information), mais uniquement grâce à des techniques génériques, permettant leur application sur la pluspart des tableaux. L'idée consiste à prendre plusieurs photos du même tableau sous différents angles. Les reflets ne dégraderons pas alors la même zone du tableau sur les différentes images et nous pourrons reconstruire à partir de ces images une image "virtuelle" sans reflets.\\

L'algorithme suggéré par l'article se décompose en deux parties. Tout d'abord, les images sont "recaléss" afin d'obtenir une perspective commune. Ainsi, les pixels des différentes images correspondent aux mêmes zones sur le tableaux, et il devient plus facile de reconstruire l'image corrigée. La seconde partie correspond justement à cette reconstructions. Plusieurs méthodes sont suggérées et nous nous sommes attachés à implémenter et comparer les différentes méthodes de fusion d'image proposées.

FIGURE - 3 ETAPES

%---------------------------------------------------> SUB SECTION Recalage des images
\subsection{Recalage des images}

Comme décrit plus haut, la première partie revient à "recaler" les images entre elles, c'est à dire simuler une perspective commune entre les photos. Sois nous pouvons nous attacher à modifier toutes les photos pour recaler l'image du tableau sur un rectangle donné, mais cela nécessite une connaissance \emph{a priori} des dimensions du tableau, que nous ne connaissons pas. Pour palier à ce problème, nous choisissons parmis les images de la peinture une photo dite de \emph{référence} et nous recadrerons les autres pour les afficher sous cette perspective.\\

Dans le cas où la caméra est idéale (modèle sténopé, pas de déformation dues à la lentille), et le tableau est parfaitement plan, la transormation permettant de recaler un tableau est une perspective. Nous n'avons pas eu besoin lors de nos traitement d'hypothèses supplémentaires.

%------------------------------------------------------------> SUB SUB SECTION Recalage manuel
\subsubsection{Recalage manuel}
Pour trouver la perspective liant deux images données, la solution la plus simple est de demander à l'utilisateur de cliquer sur 4 points communs entre les deux photos (par exemple les quatre coins du tableau). On obtient alors 2 quadrilatères quelconques, définis par les points ${p_i}_{i = 1...4}$ dans l'image de référence et ${p_i}_{i = 1...4}$ dans l'image que  l'on souhaite recaler.
On peut à partir ce ces points trouver une perspective permettant de passer du premier quadrilatère à l'autre, en effet, il existe en effet une et unique matrice $M$ en coordonées homogènes tel que

$$ \forall i \in \{1...4\}, q_i = M p_i $$

Une fois que nous avons trouvé la matrice $M$, il est possible de redresser l'image pour que les deux quadrilatères coincides, en appliquant la perspective définie par M. \\

Toutefois, il est peu probable que les valeurs de l'image de référence à échantilloner aient des coordonées entières (\emph{e.g.} des pixels). Nous devons donc pouvoir interpoler l'image de référence pour construire l'image redréssée. Plusieurs méthodes sont alors possible :

\paragraph{Interpolation au plus proche}
Pour trouver la valeur du pixel $(x,y)$ dans l'image de référence, on arrondi simplement les deux nombres pour tomber su un pixel. Cette méthode est simple à utiliser, mais moins précise que l'interpolation linéaire.

\paragraph{Interpolation Bilinéaire}
Dans cette méthode, pour trouver la valeur du pixel $(x,y)$, on observe les 4 valeur des pixels les plus proches et on interpole bilinéairement.

En pratique, nous avons choisi d'interpoller l'image de façon bilinéaire, plus précise et donc plus adaptée au travail de fusion qui viendra par la suite

\paragraph{Problème avec la méthode manuelle}

En pratique, cette méthode de recalage manuelle n'est pas utilisable pour plusieurs raisons. D'une part, le temps nécessaire pour définir les coins de chaques peinture est relativement long. D'autre part, la précision obtenue lors de nos test n'est pas suffisante pour l'étape suivante du traitement. En effet, l'utilisateur ne peux cliquer qu'avec une précision de quelques pixels au plus. Pour palier à ces problèmes, l'article suggère une solution plus automatisée, faisant appel à des descripteurs locaux.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.45\textwidth]{Fig/User_reference.png}
  \includegraphics[width=0.45\textwidth]{Fig/User_fitted.png}\\ \vspace{0.1cm}
  \includegraphics[width=0.45\textwidth]{Fig/User_average.png}

  \caption{En haut : Image de référence et image après recalage avec la méthode manuelle. En bas : Superposition des deux images. On observe des zones (particulièrement en bas à gauche) ou le recalage n'est pas bon.}
\end{figure}

%------------------------------------------------------------> SUB SUB SECTION Recalage automatique avec utilisation des  SIFT
\subsubsection{Recalage automatique avec utilisation des  SIFT}

Pour obtenir une précision sous-pixellique, nous utilisons des descripteurs locaux pour trouver des correspondances entre les deux image.

\paragraph{SIFT}
Les SIFT~\citep{lowe1999object}(Scale Invariant Feature Transform) sont des descripteurs locaux globalement inviariants aux changements de perspectives. Ils sont généralement utilisés pour détecter les correspondances entre des objets présent dans deux images différentes et sont donc très adaptés au problème actuel. Ils sont de plus invariants aux changements d'échelles et de luminosité, rendant plus robuste l'algorithme de recadrage.

FIGURE

\paragraph{Recherche de correspondances}
Nous extrayons de chaque image plusieurs centaines de SIFTs, auxquels sont associés leurs descripteurs. Nous recherchons ensuite des correspondances entre les images. Plusieurs algorithmes existent, mais le plus simple consiste à prendre pour chaque point de la première image le point le plus proche (dans l'espace des descripteurs) comme correspondant. Pour éviter d'obtenir un trop grand nombre de faux-positifs, un seuillage est effectué, nous permettant d'obtenir des correspondances point-à-point entre les deux images

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{Fig/sift_raw.png}
  \caption{Paires de descripteurs SIFT entre les deux images. Il existe encore un grand nombre de fausses-corresondances}
\end{figure}


\paragraph{RANSAC}
Il reste donc à trouver la matrice $M$ permettant de passer de l'image à recadre à l'image de référence. Contrairement au recalage manuel, il n'existe pas de tel matrice pour plus de quatre paires de points. Toutefois, si toutes les correspondances sont correctes (et il n'existe pas de faux-positifs), il est possible de trouver une matrice minimisant l'erreur $e$, par exemple par descente de gradient.

$$ e = \sum_{i = 1}^{n}\|p_i - Mq_i\|^2$$

Cependant, la présence de faux-positifs (\emph{i.e.} des paires de points qui ne correspondent pas d'une image à l'autre), il est nécessaire d'employer un algorithme plus robuste pour trouver cette homographie. La méthode RANSAC~\citep{fischler1981random} permet à la fois de filtrer les bonnes correspondances et d'obtenirs cette homographie. Cet algorithme itératif sélectionne un sous-ensemble de descripteurs aléatoirement et marque ces correspondances comme "bonnes". On cherche ensuite l'homographie la plus adaptée à cet ensemble de point (en minimisant l'erreur $e$ par exemple), puis on cherche les correspondances qui sont "d'accord" avec cette homographie (celle pour lesquelles l'erreur résiduelle est inféiruer à un certain seuil). Si suffisement de paires sont en accord avec l'homographie trouvée, elle est conservée, sinon, l'algorithme est relancé avec une nouvelle initialisation aléatoire.

Cet algorithme est extrêment robuste et peut supporter un grand nombre de faux-positifs (jusqu'à 50\% dans certains cas). Toutefois, la convergence n'est pas forcément assurée. Il y'a également un certains nombres de paramètres dont les valeurs sont à ajuster en fonction du problèmes.

En pratique toutefois, et sur la pluspart des photos, l'algorithme de RANSAC permet de trouver une bonne correspondance entre les différentes images. 

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{Fig/sift_ransac.png}
  \caption{Paires de descripteurs SIFT estimés correctes par l'algorithme RANSAC et utilisés pour renconstruire la perspective}
\end{figure}


\begin{figure}[H]
  \centering
  \includegraphics[width=0.30\textwidth]{Fig/working.png}
  \includegraphics[width=0.30\textwidth]{Fig/reference_image.png}
  \includegraphics[width=0.30\textwidth]{Fig/fitted.png}

  \caption{A gauche : image de travail, au centre : image de référence, à droite : image de travail après recalage par rapport à l'image de référence. Noter la différence de position des reflets entre l'image de référence et l'image recalée}
\end{figure}

%------------------------------------------------------------> SUB SUB SECTION Amélioration
\subsubsection{Amélioration}

Plusieurs améliorations des méthodes proposées auparavant sont possibles, tant sur le modèle que sur la robustesse du système et du traitement des données

\paragraph{Prise en compte des déformations dues à la lentilles}
La méthode proposée ci dessus est suffisante pour la pluspart des améliorations, mais n'est pas parfaites, en effet, les déformations dues à la lentille de la caméra induise des imperfections dans les images. Une simple perspective ne peux pas corriger ces déformations, et le recalage n'est pas idéal.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.45\textwidth]{Fig/Recalage_OK.png}
  \includegraphics[width=0.45\textwidth]{Fig/Recalage_flou.png}
  \caption{Détails de la moyenne de l'image recalées et de l'image de référence. A gauche, le recalage est correcte et les contours sont nets. A droite, sur le bord de l'image, le recalage est moins bon, et les contours sont flous.}
\end{figure}

Pour palier à ce problème, l'article suggère un modèle prenant en compte les déformations dues à la lentille, et se basant sur un polynôme de degré 4 $P(x,y)$. Pour trouver ce polynôme, la matrice de perspective $M$ est obtenue par l'algorithme de RANSAC, puis les points en "accord" avec cette matrice au sens de RANSAC sont utilisés pour trouver les meilleurs coefficients du polynôme. La correction à appliquer à l'image est donc 

$$ q'_i = M q_i + P(q_i) $$

\paragraph{Amélioration de la robustesse de la méthode SIFT}
Sur plusieurs jeux d'images, la méthode SIFT n'a pas été adaptée, et proposait des recalages abberants, inuitilisable pour la fusion d'image.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.25\textwidth]{Fig/error_reference.png}
  \includegraphics[width=0.25\textwidth]{Fig/error_fitted.png}
  \caption{Image de référence, et image inccorectement recalés}
\end{figure}

Deux solutions possibles peuvent venir à l'esprit. D'une part, nous pourrions rejeter automatiquement les images où le nombre de correspondances "bonnes" selon RANSAC est trop faible, et où le recalage n'est pas acceptable. D'autre part, nous pourrions demander à l'utilisateur d'indiquer grossièrement les coins du tableau. Ceci permet d'obtenir une approximation de la "bonne" perspective, et de restreindre la recherche par RANSAC à un espace plus petit.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.45\textwidth]{Fig/merge_no_rejection.png}
  \includegraphics[width=0.45\textwidth]{Fig/merge_rejection.png}
  \caption{Moyennes des images recalées sans rejet (toutes les images recalées sont gardées) et avec rejet (les images où le nombre d'inlier est trop faible est écarté)}
\end{figure}

%---------------------------------------------------> SUB SECTION Fusion des images
\subsection{Fusion des images}
Une fois les images recalées, l'étape suivante est de fusionner les images entre elles pour éliminer les reflets. Plusieurs approches sont possibles ; dans les premières approches développées ci-après, nous testons des approches qui fusionnent les images pixels par pixels, c'est-à-dire que chaque pixel de l'image reconstitué dépend uniquement des pixels correspondant dans les différentes images recalées. Ainsi, si les images recalées sont notées \( \tilde I_1, ..., \tilde I_n \), l'image fusionnée \(J\) est définie par
\[
J(x,y)=f\left(\tilde I_1(x,y), ..., \tilde I_n(x,y)\right)
\]
De nombreux choix sont possibles pour la fonction $f$. Dans la section~\ref{fusionmin}, nous proposons une fusion par minimum sur chaque canal de couleur. Nous proposons ensuite des fusions par médiane ; elle se fait par canal RGB dans la section~\ref{fusionmediane}, par médiane vectorielle dans la section~\ref{fusiontruemediane}, ou par une méthode légèrement différente dans un autre espace de couleur, détaillée dans la section~\ref{fusionlab}.\\
Il est également possible de travailler dans l'espace gradient au lieu de l'espace de l'image. Dans ce cas, l'image fusionnée J est définie par
\[
\nabla J(x,y)=f\left(\nabla \tilde I_1(x,y), ..., \nabla \tilde I_n(x,y)\right)
\]
Ce cas est détaillé dans la section~\ref{fusiongrad}.
%------------------------------------------------------------> SUB SUB SECTION Fusion par minimum
\subsubsection{Fusion par minimum}
\label{fusionmin}
Pour cette méthode, nous faisons l'hypothèse que le les reflets ne font qu'ajouter de la luminosité aux différents pixels de l'image, et que les reflets ne peuvent se retrouver dans toutes les images. Dès lors, il suffit de prendre le minimum de chaque canal de couleur pour parvenir à éliminer les reflets.
%------------------------------------------------------------> SUB SUB SECTION Fusion par médianne vectorielle
\subsubsection{Fusion par médiane car canal}
\label{fusionmediane}
\subsubsection{Fusion par médiane vectorielle}
\label{fusiontruemediane}
Une autre façon consiste à voter, pixel par pixel, pour ce qui devrait être le pixel sans reflet. On suppose ici que le reflet se trouve dans moins de la moitié des images à un endroit donné. Deux méthodes sont alors possibles. On peut prendre la médiane des pixels, canaux de couleurs par canaux de couleurs. Cette méthode, simple et intuitive, à le désavantage, comme la méthode précédente, de mélanger les canaux couleurs d'images différentes, ce qui peut conduire à des couleurs non naturelles. Pour pallier à ce problème, nous avons également implémenté un équivalent de la médiane dans l'espace vectoriel des couleurs ; il s'agit du vecteur minimisant la somme de ses distances $L_1$ aux autres vecteurs. En pratique, nous n'observons pas de différences entre ces deux médianes. 
\subsubsection{Fusion par médiane dans l'espace Lab}
\label{fusionlab}
%------------------------------------------------------------> SUB SUB SECTION Fusion dans l'espace gradient
\subsubsection{Fusion dans l'espace gradient}
\label{fusiongrad}
Enfin, une méthode décrite dans~\citep{haro2012photographing} permettant de réduire plus les reflets consiste à prendre la médiane vectorielle dans l'espace gradient des images. Pour ce faire, nous calculons les images gradients des images recalées, converties en niveau de gris, et nous en calculons la médiane vectorielle en chaque point. Ensuite, nous construisons les gradients de chaque canal de couleur de l'image fusionnée en prenant, pour chaque point et chaque canal, le gradient de l'image dont la médiane est issue. Ce sont donc bien les gradients des canaux de couleurs qui sont considérés.\\
Lorsque l'on connait le gradient $F$ d'une image, il est possible de la retrouver en minimisant $\min||\mathrm{grad}I - F||$. Ceci se fait grâce à l'équation de Poisson $\Delta I = \mathrm{div}F$. Cette équation est alors résolue, canal par canal, en passant par la transformée de Fourier, s'inspirant de~\citep{morel2010pde}. Rencontrant des difficultés dans cette dernière étape, nous n'avons pas pu terminer cette méthode. Elle donne cependant d'excellents résultats dans~\citep{haro2012photographing}, éliminant certains reflets apparaissant dans une majorité d'images.
%------------------------------------------> SECTION Implémentation
\section{Implémentation}

\subsection{Choix technique}
Nous avons implémenté la méthode décrite dans l'article à l'aide du language C++ accompagné de la librarie OpenCV~\citep{opencv_library} de traitement d'image. Cette librarie, très utilisée dans l'industrie, permet d'accélerer le traitement d'image et met à disposition de l'utilisateur plusieurs fonctions (comme par exemple l'algorithme de RANSAC, implémenté dans la fonction \texttt{findHomography}).

\subsection{Architecture}
La méthode décrite ci-dessus est fortement dépendante des paramètres d'entrées et des images à traiter. Par exemple, sur certaines images, la méthode de fusion par minimum est plus adaptée que la méthode de fusion par médianne. Il est donc nécessaire de permettre à l'utilisateur de sélectionner les différentes techniques de recalage et de fusion d'image. Ainsi, nous avons séparé les différente responsabilités entre plusieurs fichiers et classes. Plusieurs méthodes(situées dans les fichiers \texttt{ImageFitter} \texttt{ImageMerger}) permettent de sélectionner les différentes techniques possibles. 

\subsection{Collaboration}
La collaboration a été réalisé grâce au gestionnaire de version git. La totalité du code et ses révisions antérieures sont donc disponible sur Github : http://github.com/jcaille/CVCanvas

%------------------------------------------> SECTION Résultats
\section{Résultats}
Les résultats varient peu selon les méthodes (figure~\ref{mediane}). Les médianes permettent de retirer de nombreux artéfacts de reflets, mais ne fonctionnent pas là où une majorité d'images présentent des artéfacts. Les méthodes de médiane, canal par canal ou globale, donnent les mêmes résultats sur les exemples que nous avons essayés.
\begin{figure}
\centering
\begin{minipage}{0.6\linewidth}
% \includegraphics[width=\textwidth]{Fig/reference.jpg}
\end{minipage}
\begin{minipage}{0.6\linewidth}
% \includegraphics[width=\textwidth]{Fig/merge_min.jpg}
\end{minipage}
\begin{minipage}{0.6\linewidth}
% \includegraphics[width=\textwidth]{Fig/merge_median.jpg}
\end{minipage}
\caption{Correction des artéfacts. De haut en bas : image de référence, puis corrigée avec les méthodes du minimum et de la médiane.}
\label{mediane}
\end{figure} 
%------------------------------------------> SECTION Améliorations possibles
\section{Améliorations possibles}

Plusieurs amélioration de l'algorithme sont envisageables. Si les images obtenues sont de bonne qualité, l'algorithme ne sait pas faire la différence entre les zones de la peinture et les zones extérieures (cadre, mur, paysage, ...), dans lesquelles la fusion est effectuée alors qu'elle n'a pas de sens. Une possibilité pour détecter ces zones et de segmenter l'image de référence (par exemple en utilisant des snakes quadrangulaires) entre un "intérieur" sur lequel la fusion serait effectué et un extérieur sur lequel on garderait le contenu d'origine. Pour s'aider dans cette segmentation, nous pourrions utiliser les informations des autres photos du tableau.

De plus, l'algorithme que nous avons développé (en particulier la partie de fusion) n'est pas de fait résistant aux changements de contrastes en général. Une idée pour corriger ce défaut serait d'égaliser les histogrammes les différentes images (de préférence en limitant cette égalisation à la zone "intérieur" du tableau).
\bibliographystyle{plain}
\bibliography{QUEEN}
\end{document}
